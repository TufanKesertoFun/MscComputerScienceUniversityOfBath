{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the spam training data set: (1000, 55)\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [1 1 1 ... 1 1 0]\n",
      " [1 0 0 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.display import HTML,Javascript, display\n",
    "\n",
    "training_spam = np.loadtxt(open(\"data/training_spam.csv\"), delimiter=\",\").astype(int)\n",
    "print(\"Shape of the spam training data set:\", training_spam.shape)\n",
    "print(training_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the spam testing data set: (500, 55)\n",
      "[[1 0 0 ... 1 1 1]\n",
      " [1 1 0 ... 1 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "testing_spam = np.loadtxt(open(\"data/testing_spam.csv\"), delimiter=\",\").astype(int)\n",
    "print(\"Shape of the spam testing data set:\", testing_spam.shape)\n",
    "print(testing_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the spam training data set: (1000, 55)\n",
      "Shape of the spam testing data set: (500, 55)\n",
      "Learning Rate: 0.001, Epochs: 500, Accuracy: 0.9200, Time: 0.13s\n",
      "Learning Rate: 0.001, Epochs: 1000, Accuracy: 0.9200, Time: 0.24s\n",
      "Learning Rate: 0.001, Epochs: 1500, Accuracy: 0.9300, Time: 0.35s\n",
      "Learning Rate: 0.01, Epochs: 500, Accuracy: 0.9350, Time: 0.12s\n",
      "Learning Rate: 0.01, Epochs: 1000, Accuracy: 0.9350, Time: 0.21s\n",
      "Learning Rate: 0.01, Epochs: 1500, Accuracy: 0.9400, Time: 0.35s\n",
      "Learning Rate: 0.1, Epochs: 500, Accuracy: 0.9450, Time: 0.11s\n",
      "Learning Rate: 0.1, Epochs: 1000, Accuracy: 0.9500, Time: 0.21s\n",
      "Learning Rate: 0.1, Epochs: 1500, Accuracy: 0.9500, Time: 0.36s\n",
      "Best Hyperparameters: {'learning_rate': 0.1, 'epochs': 1000}, Best Validation Accuracy: 0.9500\n",
      "Test Accuracy: 0.9220\n",
      "Predictions on Test Set: [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 1\n",
      " 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 0 1 1 0 1\n",
      " 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 1 0 1 1 0 0 1 0\n",
      " 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 1 1 1\n",
      " 0 0 1 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 1 1 0 0 1 0 0 1 1 1\n",
      " 0 1 0 0 0 1 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "import time\n",
    "\n",
    "class SpamClassifier:\n",
    "    def __init__(self, k, learning_rate=0.01, epochs=1000):\n",
    "        self.k = k  # Unused for logistic regression but kept for compatibility\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        # Initialize weights and bias\n",
    "        n_features = X_train.shape[1]\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # Gradient Descent\n",
    "        for _ in range(self.epochs):\n",
    "            linear_model = np.dot(X_train, self.weights) + self.bias\n",
    "            predictions = self.sigmoid(linear_model)\n",
    "            \n",
    "            # Compute gradients\n",
    "            dw = np.dot(X_train.T, (predictions - y_train)) / len(y_train)\n",
    "            db = np.sum(predictions - y_train) / len(y_train)\n",
    "            \n",
    "            # Update weights and bias\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "            \n",
    "    def predict(self, X_test):\n",
    "        linear_model = np.dot(X_test, self.weights) + self.bias\n",
    "        predictions = self.sigmoid(linear_model)\n",
    "        return np.where(predictions >= 0.5, 1, 0)\n",
    "\n",
    "def evaluate_model(classifier, X_val, y_val):\n",
    "    predictions = classifier.predict(X_val)\n",
    "    accuracy = np.mean(predictions == y_val)\n",
    "    return accuracy\n",
    "\n",
    "def hyperparameter_tuning(X_train, y_train, X_val, y_val, learning_rates, epochs_list):\n",
    "    best_accuracy = 0\n",
    "    best_params = {}\n",
    "    \n",
    "    for lr, epochs in product(learning_rates, epochs_list):\n",
    "        start_time = time.time()\n",
    "        classifier = SpamClassifier(k=1, learning_rate=lr, epochs=epochs)\n",
    "        classifier.train(X_train, y_train)\n",
    "        accuracy = evaluate_model(classifier, X_val, y_val)\n",
    "        end_time = time.time()\n",
    "\n",
    "        print(f\"Learning Rate: {lr}, Epochs: {epochs}, Accuracy: {accuracy:.4f}, Time: {end_time - start_time:.2f}s\")\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = {'learning_rate': lr, 'epochs': epochs}\n",
    "    \n",
    "    return best_params, best_accuracy\n",
    "\n",
    "# Load training and testing data\n",
    "training_spam = np.loadtxt(open(\"data/training_spam.csv\"), delimiter=\",\").astype(int)\n",
    "testing_spam = np.loadtxt(open(\"data/testing_spam.csv\"), delimiter=\",\").astype(int)\n",
    "\n",
    "print(\"Shape of the spam training data set:\", training_spam.shape)\n",
    "print(\"Shape of the spam testing data set:\", testing_spam.shape)\n",
    "\n",
    "# Split into features and labels\n",
    "X = training_spam[:, 1:]  # Features\n",
    "y = training_spam[:, 0]   # Labels\n",
    "\n",
    "# Split training data into training and validation sets (e.g., 80% train, 20% validation)\n",
    "split_index = int(0.8 * len(X))\n",
    "X_train, X_val = X[:split_index], X[split_index:]\n",
    "y_train, y_val = y[:split_index], y[split_index:]\n",
    "\n",
    "X_test = testing_spam[:, 1:]    # Test features\n",
    "y_test = testing_spam[:, 0]     # Test labels (if available)\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "epochs_list = [500, 1000, 1500]\n",
    "\n",
    "best_params, best_accuracy = hyperparameter_tuning(X_train, y_train, X_val, y_val, learning_rates, epochs_list)\n",
    "print(f\"Best Hyperparameters: {best_params}, Best Validation Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Train with Best Hyperparameters\n",
    "classifier = SpamClassifier(k=1, learning_rate=best_params['learning_rate'], epochs=best_params['epochs'])\n",
    "classifier.train(X_train, y_train)\n",
    "\n",
    "# Evaluate on Test Set\n",
    "predictions = classifier.predict(X_test)\n",
    "test_accuracy = np.mean(predictions == y_test) if len(y_test) > 0 else None\n",
    "\n",
    "if test_accuracy is not None:\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "else:\n",
    "    print(\"No labels provided for the test set.\")\n",
    "\n",
    "# Show Predictions\n",
    "print(\"Predictions on Test Set:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "import time\n",
    "\n",
    "class XGBoostSpamClassifier:\n",
    "    def __init__(self, k, learning_rate=0.1, epochs=100):\n",
    "        self.k = k  # Compatibility with template\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.trees = []\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        predictions = np.zeros(len(y_train))\n",
    "        for _ in range(self.epochs):\n",
    "            residuals = y_train - predictions\n",
    "            tree = self.simple_tree(X_train, residuals)\n",
    "            predictions += self.learning_rate * tree.predict(X_train)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def simple_tree(self, X, y):\n",
    "        feature_idx = np.argmax(np.var(X, axis=0))\n",
    "        threshold = np.median(X[:, feature_idx])\n",
    "\n",
    "        class Tree:\n",
    "            def __init__(self, left_value, right_value, feature_idx, threshold):\n",
    "                self.left_value = left_value\n",
    "                self.right_value = right_value\n",
    "                self.feature_idx = feature_idx\n",
    "                self.threshold = threshold\n",
    "\n",
    "            def predict(self, X):\n",
    "                return np.where(X[:, self.feature_idx] < self.threshold, self.left_value, self.right_value)\n",
    "\n",
    "        left_value = np.mean(y[X[:, feature_idx] < threshold])\n",
    "        right_value = np.mean(y[X[:, feature_idx] >= threshold])\n",
    "\n",
    "        return Tree(left_value, right_value, feature_idx, threshold)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = np.zeros(X_test.shape[0])\n",
    "        for tree in self.trees:\n",
    "            predictions += self.learning_rate * tree.predict(X_test)\n",
    "        return np.where(predictions >= 0.5, 1, 0)\n",
    "\n",
    "\n",
    "def evaluate_model(classifier, X_val, y_val):\n",
    "    predictions = classifier.predict(X_val)\n",
    "    accuracy = np.mean(predictions == y_val)\n",
    "    return accuracy\n",
    "\n",
    "def hyperparameter_tuning(X_train, y_train, X_val, y_val, learning_rates, epochs_list):\n",
    "    best_accuracy = 0\n",
    "    best_params = {}\n",
    "    \n",
    "    for lr, epochs in product(learning_rates, epochs_list):\n",
    "        start_time = time.time()\n",
    "        classifier = XGBoostSpamClassifier(k=1, learning_rate=lr, epochs=epochs)\n",
    "        classifier.train(X_train, y_train)\n",
    "        accuracy = evaluate_model(classifier, X_val, y_val)\n",
    "        end_time = time.time()\n",
    "\n",
    "        print(f\"Learning Rate: {lr}, Epochs: {epochs}, Accuracy: {accuracy:.4f}, Time: {end_time - start_time:.2f}s\")\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = {'learning_rate': lr, 'epochs': epochs}\n",
    "    \n",
    "    return best_params, best_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Running Hyperparameter Tuning for Each Model...\n",
      "\n",
      "XGBoostSpamClassifier - LR: 0.001, Epochs: 500, Accuracy: 0.3900, Time: 0.05s\n",
      "XGBoostSpamClassifier - LR: 0.001, Epochs: 1000, Accuracy: 0.3900, Time: 0.11s\n",
      "XGBoostSpamClassifier - LR: 0.001, Epochs: 1500, Accuracy: 0.3900, Time: 0.15s\n",
      "XGBoostSpamClassifier - LR: 0.01, Epochs: 500, Accuracy: 0.5150, Time: 0.04s\n",
      "XGBoostSpamClassifier - LR: 0.01, Epochs: 1000, Accuracy: 0.5150, Time: 0.09s\n",
      "XGBoostSpamClassifier - LR: 0.01, Epochs: 1500, Accuracy: 0.5150, Time: 0.14s\n",
      "XGBoostSpamClassifier - LR: 0.1, Epochs: 500, Accuracy: 0.5150, Time: 0.05s\n",
      "XGBoostSpamClassifier - LR: 0.1, Epochs: 1000, Accuracy: 0.5150, Time: 0.09s\n",
      "XGBoostSpamClassifier - LR: 0.1, Epochs: 1500, Accuracy: 0.5150, Time: 0.14s\n",
      "Best Params for XGBoostSpamClassifier: {'learning_rate': 0.01, 'epochs': 500}, Best Accuracy: 0.5150\n",
      "LightGBMSpamClassifier - LR: 0.001, Epochs: 500, Accuracy: 0.3900, Time: 0.05s\n",
      "LightGBMSpamClassifier - LR: 0.001, Epochs: 1000, Accuracy: 0.3900, Time: 0.09s\n",
      "LightGBMSpamClassifier - LR: 0.001, Epochs: 1500, Accuracy: 0.3900, Time: 0.14s\n",
      "LightGBMSpamClassifier - LR: 0.01, Epochs: 500, Accuracy: 0.5150, Time: 0.05s\n",
      "LightGBMSpamClassifier - LR: 0.01, Epochs: 1000, Accuracy: 0.5150, Time: 0.09s\n",
      "LightGBMSpamClassifier - LR: 0.01, Epochs: 1500, Accuracy: 0.5150, Time: 0.14s\n",
      "LightGBMSpamClassifier - LR: 0.1, Epochs: 500, Accuracy: 0.5150, Time: 0.04s\n",
      "LightGBMSpamClassifier - LR: 0.1, Epochs: 1000, Accuracy: 0.5150, Time: 0.09s\n",
      "LightGBMSpamClassifier - LR: 0.1, Epochs: 1500, Accuracy: 0.5150, Time: 0.14s\n",
      "Best Params for LightGBMSpamClassifier: {'learning_rate': 0.01, 'epochs': 500}, Best Accuracy: 0.5150\n",
      "CatBoostSpamClassifier - LR: 0.001, Epochs: 500, Accuracy: 0.3900, Time: 0.04s\n",
      "CatBoostSpamClassifier - LR: 0.001, Epochs: 1000, Accuracy: 0.3900, Time: 0.09s\n",
      "CatBoostSpamClassifier - LR: 0.001, Epochs: 1500, Accuracy: 0.3900, Time: 0.14s\n",
      "CatBoostSpamClassifier - LR: 0.01, Epochs: 500, Accuracy: 0.5150, Time: 0.04s\n",
      "CatBoostSpamClassifier - LR: 0.01, Epochs: 1000, Accuracy: 0.5150, Time: 0.09s\n",
      "CatBoostSpamClassifier - LR: 0.01, Epochs: 1500, Accuracy: 0.5150, Time: 0.14s\n",
      "CatBoostSpamClassifier - LR: 0.1, Epochs: 500, Accuracy: 0.5150, Time: 0.04s\n",
      "CatBoostSpamClassifier - LR: 0.1, Epochs: 1000, Accuracy: 0.5150, Time: 0.11s\n",
      "CatBoostSpamClassifier - LR: 0.1, Epochs: 1500, Accuracy: 0.5150, Time: 0.14s\n",
      "Best Params for CatBoostSpamClassifier: {'learning_rate': 0.01, 'epochs': 500}, Best Accuracy: 0.5150\n",
      "SVMSpamClassifier - LR: 0.001, Epochs: 500, Accuracy: 0.4850, Time: 1.82s\n",
      "SVMSpamClassifier - LR: 0.001, Epochs: 1000, Accuracy: 0.4650, Time: 3.65s\n",
      "SVMSpamClassifier - LR: 0.001, Epochs: 1500, Accuracy: 0.4650, Time: 5.46s\n",
      "SVMSpamClassifier - LR: 0.01, Epochs: 500, Accuracy: 0.5950, Time: 1.80s\n",
      "SVMSpamClassifier - LR: 0.01, Epochs: 1000, Accuracy: 0.5950, Time: 3.59s\n",
      "SVMSpamClassifier - LR: 0.01, Epochs: 1500, Accuracy: 0.5950, Time: 5.37s\n",
      "SVMSpamClassifier - LR: 0.1, Epochs: 500, Accuracy: 0.6100, Time: 1.65s\n",
      "SVMSpamClassifier - LR: 0.1, Epochs: 1000, Accuracy: 0.6100, Time: 3.31s\n",
      "SVMSpamClassifier - LR: 0.1, Epochs: 1500, Accuracy: 0.6100, Time: 4.93s\n",
      "Best Params for SVMSpamClassifier: {'learning_rate': 0.1, 'epochs': 500}, Best Accuracy: 0.6100\n",
      "NeuralNetworkSpamClassifier - LR: 0.001, Epochs: 500, Accuracy: 0.6100, Time: 0.05s\n",
      "NeuralNetworkSpamClassifier - LR: 0.001, Epochs: 1000, Accuracy: 0.6100, Time: 0.09s\n",
      "NeuralNetworkSpamClassifier - LR: 0.001, Epochs: 1500, Accuracy: 0.6100, Time: 0.14s\n",
      "NeuralNetworkSpamClassifier - LR: 0.01, Epochs: 500, Accuracy: 0.5050, Time: 0.04s\n",
      "NeuralNetworkSpamClassifier - LR: 0.01, Epochs: 1000, Accuracy: 0.4850, Time: 0.09s\n",
      "NeuralNetworkSpamClassifier - LR: 0.01, Epochs: 1500, Accuracy: 0.4800, Time: 0.14s\n",
      "NeuralNetworkSpamClassifier - LR: 0.1, Epochs: 500, Accuracy: 0.6000, Time: 0.05s\n",
      "NeuralNetworkSpamClassifier - LR: 0.1, Epochs: 1000, Accuracy: 0.5250, Time: 0.09s\n",
      "NeuralNetworkSpamClassifier - LR: 0.1, Epochs: 1500, Accuracy: 0.4650, Time: 0.14s\n",
      "Best Params for NeuralNetworkSpamClassifier: {'learning_rate': 0.001, 'epochs': 500}, Best Accuracy: 0.6100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.001, 'epochs': 500}, 0.61)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "import time\n",
    "\n",
    "# ==============================\n",
    "# EVALUATION FUNCTION\n",
    "# ==============================\n",
    "def evaluate_model(classifier, X_val, y_val):\n",
    "    predictions = classifier.predict(X_val)\n",
    "    accuracy = np.mean(predictions == y_val)\n",
    "    return accuracy\n",
    "\n",
    "# ==============================\n",
    "# HYPERPARAMETER TUNING FUNCTION\n",
    "# ==============================\n",
    "def hyperparameter_tuning(ClassifierClass, X_train, y_train, X_val, y_val, learning_rates, epochs_list):\n",
    "    best_accuracy = 0\n",
    "    best_params = {}\n",
    "    \n",
    "    for lr, epochs in product(learning_rates, epochs_list):\n",
    "        start_time = time.time()\n",
    "        classifier = ClassifierClass(k=1, learning_rate=lr, epochs=epochs)\n",
    "        classifier.train(X_train, y_train)\n",
    "        accuracy = evaluate_model(classifier, X_val, y_val)\n",
    "        end_time = time.time()\n",
    "\n",
    "        print(f\"{ClassifierClass.__name__} - LR: {lr}, Epochs: {epochs}, Accuracy: {accuracy:.4f}, Time: {end_time - start_time:.2f}s\")\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = {'learning_rate': lr, 'epochs': epochs}\n",
    "    \n",
    "    print(f\"Best Params for {ClassifierClass.__name__}: {best_params}, Best Accuracy: {best_accuracy:.4f}\")\n",
    "    return best_params, best_accuracy\n",
    "\n",
    "# ==============================\n",
    "# SIMPLE DECISION TREE (FOR BOOSTING MODELS)\n",
    "# ==============================\n",
    "class SimpleDecisionTree:\n",
    "    def fit(self, X, y):\n",
    "        feature_idx = np.argmax(np.var(X, axis=0))\n",
    "        threshold = np.median(X[:, feature_idx])\n",
    "        self.feature_idx = feature_idx\n",
    "        self.threshold = threshold\n",
    "        self.left_value = np.mean(y[X[:, feature_idx] < threshold])\n",
    "        self.right_value = np.mean(y[X[:, feature_idx] >= threshold])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.where(X[:, self.feature_idx] < self.threshold, self.left_value, self.right_value)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 1️⃣ XGBoost Classifier\n",
    "# ==============================\n",
    "class XGBoostSpamClassifier:\n",
    "    def __init__(self, k, learning_rate=0.1, epochs=100):\n",
    "        self.k = k\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.trees = []\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        predictions = np.zeros(len(y_train))\n",
    "        for _ in range(self.epochs):\n",
    "            residuals = y_train - predictions\n",
    "            tree = SimpleDecisionTree()\n",
    "            tree.fit(X_train, residuals)\n",
    "            predictions += self.learning_rate * tree.predict(X_train)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = np.zeros(X_test.shape[0])\n",
    "        for tree in self.trees:\n",
    "            predictions += self.learning_rate * tree.predict(X_test)\n",
    "        return np.where(predictions >= 0.5, 1, 0)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 2️⃣ LightGBM Classifier\n",
    "# ==============================\n",
    "class LightGBMSpamClassifier:\n",
    "    def __init__(self, k, learning_rate=0.1, epochs=100):\n",
    "        self.k = k\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.trees = []\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        predictions = np.zeros(len(y_train))\n",
    "        for _ in range(self.epochs):\n",
    "            residuals = y_train - predictions\n",
    "            tree = SimpleDecisionTree()\n",
    "            tree.fit(X_train, residuals)\n",
    "            predictions += self.learning_rate * tree.predict(X_train)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = np.zeros(X_test.shape[0])\n",
    "        for tree in self.trees:\n",
    "            predictions += self.learning_rate * tree.predict(X_test)\n",
    "        return np.where(predictions >= 0.5, 1, 0)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 3️⃣ CatBoost Classifier\n",
    "# ==============================\n",
    "class CatBoostSpamClassifier:\n",
    "    def __init__(self, k, learning_rate=0.1, epochs=100):\n",
    "        self.k = k\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.trees = []\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        predictions = np.zeros(len(y_train))\n",
    "        for _ in range(self.epochs):\n",
    "            residuals = y_train - predictions\n",
    "            tree = SimpleDecisionTree()\n",
    "            tree.fit(X_train, residuals)\n",
    "            predictions += self.learning_rate * tree.predict(X_train)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = np.zeros(X_test.shape[0])\n",
    "        for tree in self.trees:\n",
    "            predictions += self.learning_rate * tree.predict(X_test)\n",
    "        return np.where(predictions >= 0.5, 1, 0)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 4️⃣ SVM Classifier\n",
    "# ==============================\n",
    "class SVMSpamClassifier:\n",
    "    def __init__(self, k, learning_rate=0.001, epochs=1000, lambda_param=0.01):\n",
    "        self.k = k\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.lambda_param = lambda_param\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        y_train = np.where(y_train <= 0, -1, 1)\n",
    "        n_features = X_train.shape[1]\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            for idx, x_i in enumerate(X_train):\n",
    "                condition = y_train[idx] * (np.dot(x_i, self.weights) - self.bias) >= 1\n",
    "                if condition:\n",
    "                    self.weights -= self.learning_rate * (2 * self.lambda_param * self.weights)\n",
    "                else:\n",
    "                    self.weights -= self.learning_rate * (2 * self.lambda_param * self.weights - np.dot(x_i, y_train[idx]))\n",
    "                    self.bias -= self.learning_rate * y_train[idx]\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        linear_output = np.dot(X_test, self.weights) - self.bias\n",
    "        return np.where(linear_output >= 0, 1, 0)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 5️⃣ Neural Network Classifier\n",
    "# ==============================\n",
    "class NeuralNetworkSpamClassifier:\n",
    "    def __init__(self, k, learning_rate=0.1, epochs=1000, hidden_size=10):\n",
    "        self.k = k\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        n_features = X_train.shape[1]\n",
    "        self.weights_input_hidden = np.random.randn(n_features, self.hidden_size) * 0.01\n",
    "        self.weights_hidden_output = np.random.randn(self.hidden_size, 1) * 0.01\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            hidden_layer = self.sigmoid(np.dot(X_train, self.weights_input_hidden))\n",
    "            output_layer = self.sigmoid(np.dot(hidden_layer, self.weights_hidden_output))\n",
    "\n",
    "            error = y_train.reshape(-1, 1) - output_layer\n",
    "            output_delta = error * self.sigmoid_derivative(output_layer)\n",
    "            hidden_delta = output_delta.dot(self.weights_hidden_output.T) * self.sigmoid_derivative(hidden_layer)\n",
    "\n",
    "            self.weights_hidden_output += hidden_layer.T.dot(output_delta) * self.learning_rate\n",
    "            self.weights_input_hidden += X_train.T.dot(hidden_delta) * self.learning_rate\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        hidden_layer = self.sigmoid(np.dot(X_test, self.weights_input_hidden))\n",
    "        output_layer = self.sigmoid(np.dot(hidden_layer, self.weights_hidden_output))\n",
    "        return np.where(output_layer >= 0.5, 1, 0).flatten()\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# LOAD SPAM DATA (SIMULATED FOR NOW)\n",
    "# ==============================\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(1000, 55)  # 1000 samples, 20 features\n",
    "y = np.random.randint(0, 2, 1000)\n",
    "\n",
    "split_index = int(0.8 * len(X))\n",
    "X_train, X_val = X[:split_index], X[split_index:]\n",
    "y_train, y_val = y[:split_index], y[split_index:]\n",
    "\n",
    "X_test = np.random.rand(200, 55)\n",
    "y_test = np.random.randint(0, 2, 200)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# HYPERPARAMETER SETTINGS\n",
    "# ==============================\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "epochs_list = [500, 1000, 1500]\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# RUN AND DISPLAY ACCURACY FOR EACH MODEL\n",
    "# ==============================\n",
    "\n",
    "print(\"\\n🔍 Running Hyperparameter Tuning for Each Model...\\n\")\n",
    "\n",
    "# 1️⃣ XGBoost\n",
    "hyperparameter_tuning(XGBoostSpamClassifier, X_train, y_train, X_val, y_val, learning_rates, epochs_list)\n",
    "\n",
    "# 2️⃣ LightGBM\n",
    "hyperparameter_tuning(LightGBMSpamClassifier, X_train, y_train, X_val, y_val, learning_rates, epochs_list)\n",
    "\n",
    "# 3️⃣ CatBoost\n",
    "hyperparameter_tuning(CatBoostSpamClassifier, X_train, y_train, X_val, y_val, learning_rates, epochs_list)\n",
    "\n",
    "# 4️⃣ SVM\n",
    "hyperparameter_tuning(SVMSpamClassifier, X_train, y_train, X_val, y_val, learning_rates, epochs_list)\n",
    "\n",
    "# 5️⃣ Neural Network\n",
    "hyperparameter_tuning(NeuralNetworkSpamClassifier, X_train, y_train, X_val, y_val, learning_rates, epochs_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
